# 训练

项目根目录:

ChatGLM-Efficient-Tuning: `/root/haoyu/ChatGLM-Efficient-Tuning-main`

手动训练: `/root/train`

训练接口: `/root/hw/训练接口`

运行环境:

`conda activate hw`

## 写在前头

1. 由于Langchain使用内部Loader加载模型，无法在知识库模型上线后动态更改权重。如果需要在知识库中更改模型，需要手动合并LoRA权重，并将模型导出, 改变`/root/hw/Langchain-Chatchat`中的model_config.py中的模型路径。此处的训练和动态部署仅适用于`python /root/haoyu/ChatGLM2-6B/api_lora_hw.py`启动的模型接口
2. 如果需要使用到训练的全部功能，包括调整epoch, 学习率等，请移步至`/root/haoyu/ChatGLM-Efficient-Tuning-main`并阅读开源项目的[文档](https://github.com/hiyouga/ChatGLM-Efficient-Tuning)进行训练。

## 代码结构

|文件名|作用|启动命令|关闭命令|
|:---:|:---|:---|:---|
|/root/haoyu/ChatGLM-Efficient-Tuning-main/manual_train/manual_train.py|手动训练|推荐在`/root/train`目录下使用`train`命令启动，直接在`/root/haoyu/ChatGLM-Efficient-Tuning-main`目录下`python manual_train/manual_train.py`也可以.|`kill -9 <PID>`|
|/root/haoyu/ChatGLM-Efficient-Tuning-main/manual_train/dataset.py|手动训练使用到的操作数据集的模块|无，仅为手动训练模块|无，仅为手动训练模块|
|/root/hw/训练接口/api_train.py|训练接口代码|`./deploy.sh`|`kill -9 <PID>`|

## 手动训练(推荐)

训练示意图:

![](/images/docs/乐唯/图片1.jpg)

#### 步骤

1. 清洗, 放入数据 
2. last_checkpoint.json确定起点checkpoint 
3. train命令训练 
4. gpu命令监视显存，查看log和training_log.log观察结束时间 
5. 训练结束，使用change_model.ipynb改变部署模型 
6. 使用dtest <问题> 查看模型表现 
7. 若模型表现不错，记录此checkpoint *注: last_checkpoint.json中的模型checkpoint起点将会自动变为刚刚结束训练的这个checkpoint，如果需要回退模型，需要自己改变last_checkpoint.json中的训练起点。*

![](/images/docs/乐唯/图片2.png)

现在的训练是后台训练，只能通过kill -9 <PID>的方式关闭。这个方法在之后会提到。
同时在输入train之后，可能需要手动回车后才能使用终端。

![](/images/docs/乐唯/图片3.png)

1.	训练的本质是从一个checkpoint到达另一个checkpoint.
2.	现在最新的checkpoint叫`loovee-checkpoint-v4`，模型名字是薯遇, 可以完成生成问候语的任务。
3.	没有任何训练的checkpoint是base_model，适合作为一切训练的起点。 （注，需求此时还在确定模型身份，所以可以先重新训练乱码和红娘话术等身份无关的数据）
4.	**每次训练的数据一定要大于等于两条**。

上述checkpoints都在train文件夹的more/important_files里面

![](/images/docs/乐唯/图片4.png)

在 more/tools文件夹中，有三个可以使用的很有用的工具，功能依照名字, 分别是改变模型权重、敏感词redis快速操作、测试部署模型。

![](/images/docs/乐唯/图片5.png)

Change_model.ipynb可以直接改变部署的模型，可以用于测试用, 运行一次10秒左右。

![](/images/docs/乐唯/图片6.png)

改变json_中model_path中的内容，运行后将会直接改变部署的模型。用于测试比较管用。改变模型后，可以结合dtest使用。

![](/images/docs/乐唯/图片7.png)


redis.ipynb用于敏感词数据库的操作。其中包括删除命令，请谨慎使用。
test_deploy.ipynb 用于测试部署的模型。

训练得到的checkpoints会保存到`checkpoints` 文件夹中

![](/images/docs/乐唯/图片8.png)

#### 测试相关

dtest <问题> 可以直接与模型对话。(dtest stands for deploy test)

![](/images/docs/乐唯/图片9.png)

敏感词检查工作流程：

![](/images/docs/乐唯/图片10.png)

使用 `dtest 开始训练` 将会直接开始训练，这里不推荐使用，因为会让对话接口完全无法使用。

#### 显卡监控

输入gpu回车可以查看gpu使用状况

![](/images/docs/乐唯/图片11.png)

![](/images/docs/乐唯/图片12.png)

建议新建一个单独的窗口使用gpu命令。

#### 模型信息

![](/images/docs/乐唯/图片14.png)

#### 补充

训练后的数据会被放在 trained_data中：

![](/images/docs/乐唯/图片16.png)

#### 常见bug

Training_log.log中若有这个错误：

`AssertionError: Provided path xxx does not contain a LoRA weight.`

![](/images/docs/乐唯/图片17.png)

说明起点checkpoint不存在或者起点checkpoint上次训练失败了，改变起点`last_checkpoint`即可解决问题.

![](/images/docs/乐唯/图片18.png)


## 前端训练/半自动训练(不推荐)

![](/images/docs/乐唯/图片1.png)

![](/images/docs/乐唯/图片2_.png)

> 注: 训练模型时模型对话接口将会完全停止，请谨慎使用

> 正向“教导”AI模型较为简单，但要将模型反向”矫正”过来非常困难。所以，数据质量很重要，对模型姓名、模型开发者等重要背景信息，需要提前做出统一决定再进行训练(比如，是叫小薯条，还是叫薯遇)。您进行的每一次训练都举足轻重。如果模型出现了一些问题，只能通过回退到上一个模型检查点来解决。

## 训练接口


* temp_data: 训练接口获得的前端数据的存储位置
	* 会以 Loovee-<当日日期> 的格式存储
	* 其中的训练数据将会以类似 `2023-08-08-16:57:56.json` 的 `日期-时间` 命名格式存储

* trained_data: 已训练过的数据

![](/images/docs/乐唯/Snipaste_2023-08-24_16-19-00.png)


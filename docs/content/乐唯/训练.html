
<!DOCTYPE html>
<html>
<head>
    <link href="/images/favicon.ico" rel="icon" type="/image/x-icon" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/docs/github.css">
</head>
<div class = "spacing-div">
<article class="markdown-body">
<h1><a id="user-content-训练" class="anchor" aria-hidden="true" href="#训练"><span aria-hidden="true" class="octicon octicon-link"></span></a>训练</h1>
<p>项目根目录:</p>
<p>ChatGLM-Efficient-Tuning: <code>/root/haoyu/ChatGLM-Efficient-Tuning-main</code></p>
<p>手动训练: <code>/root/train</code></p>
<p>训练接口: <code>/root/hw/训练接口</code></p>
<p>运行环境:</p>
<p><code>conda activate hw</code></p>
<h2><a id="user-content-写在前头" class="anchor" aria-hidden="true" href="#写在前头"><span aria-hidden="true" class="octicon octicon-link"></span></a>写在前头</h2>
<ol>
<li>由于Langchain使用内部Loader加载模型，无法在知识库模型上线后动态更改权重。如果需要在知识库中更改模型，需要手动合并LoRA权重，并将模型导出, 改变<code>/root/hw/Langchain-Chatchat</code>中的model_config.py中的模型路径。此处的训练和动态部署仅适用于<code>python /root/haoyu/ChatGLM2-6B/api_lora_hw.py</code>启动的模型接口</li>
<li>如果需要使用到训练的全部功能，包括调整epoch, 学习率等，请移步至<code>/root/haoyu/ChatGLM-Efficient-Tuning-main</code>并阅读开源项目的<a href="https://github.com/hiyouga/ChatGLM-Efficient-Tuning">文档</a>进行训练。</li>
</ol>
<h2><a id="user-content-代码结构" class="anchor" aria-hidden="true" href="#代码结构"><span aria-hidden="true" class="octicon octicon-link"></span></a>代码结构</h2>
<table>
<thead>
<tr>
<th align="center">文件名</th>
<th align="left">作用</th>
<th align="left">启动命令</th>
<th align="left">关闭命令</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">/root/haoyu/ChatGLM-Efficient-Tuning-main/manual_train/manual_train.py</td>
<td align="left">手动训练</td>
<td align="left">推荐在<code>/root/train</code>目录下使用<code>train</code>命令启动，直接在<code>/root/haoyu/ChatGLM-Efficient-Tuning-main</code>目录下<code>python manual_train/manual_train.py</code>也可以.</td>
<td align="left"><code>kill -9 &lt;PID&gt;</code></td>
</tr>
<tr>
<td align="center">/root/haoyu/ChatGLM-Efficient-Tuning-main/manual_train/dataset.py</td>
<td align="left">手动训练使用到的操作数据集的模块</td>
<td align="left">无，仅为手动训练模块</td>
<td align="left">无，仅为手动训练模块</td>
</tr>
<tr>
<td align="center">/root/hw/训练接口/api_train.py</td>
<td align="left">训练接口代码</td>
<td align="left"><code>./deploy.sh</code></td>
<td align="left"><code>kill -9 &lt;PID&gt;</code></td>
</tr>
</tbody>
</table>
<h2><a id="user-content-手动训练推荐" class="anchor" aria-hidden="true" href="#手动训练推荐"><span aria-hidden="true" class="octicon octicon-link"></span></a>手动训练(推荐)</h2>
<p>训练示意图:</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%871.jpg"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%871.jpg" alt="" style="max-width: 100%;"></a></p>
<h4><a id="user-content-步骤" class="anchor" aria-hidden="true" href="#步骤"><span aria-hidden="true" class="octicon octicon-link"></span></a>步骤</h4>
<ol>
<li>清洗, 放入数据</li>
<li>last_checkpoint.json确定起点checkpoint</li>
<li>train命令训练</li>
<li>gpu命令监视显存，查看log和training_log.log观察结束时间</li>
<li>训练结束，使用change_model.ipynb改变部署模型</li>
<li>使用dtest &lt;问题&gt; 查看模型表现</li>
<li>若模型表现不错，记录此checkpoint <em>注: last_checkpoint.json中的模型checkpoint起点将会自动变为刚刚结束训练的这个checkpoint，如果需要回退模型，需要自己改变last_checkpoint.json中的训练起点。</em>
</li>
</ol>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%872.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%872.png" alt="" style="max-width: 100%;"></a></p>
<p>现在的训练是后台训练，只能通过kill -9 的方式关闭。这个方法在之后会提到。
同时在输入train之后，可能需要手动回车后才能使用终端。</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%873.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%873.png" alt="" style="max-width: 100%;"></a></p>
<ol>
<li>训练的本质是从一个checkpoint到达另一个checkpoint.</li>
<li>现在最新的checkpoint叫<code>loovee-checkpoint-v4</code>，模型名字是薯遇, 可以完成生成问候语的任务。</li>
<li>没有任何训练的checkpoint是base_model，适合作为一切训练的起点。 （注，需求此时还在确定模型身份，所以可以先重新训练乱码和红娘话术等身份无关的数据）</li>
<li>
<strong>每次训练的数据一定要大于等于两条</strong>。</li>
</ol>
<p>上述checkpoints都在train文件夹的more/important_files里面</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%874.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%874.png" alt="" style="max-width: 100%;"></a></p>
<p>在 more/tools文件夹中，有三个可以使用的很有用的工具，功能依照名字, 分别是改变模型权重、敏感词redis快速操作、测试部署模型。</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%875.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%875.png" alt="" style="max-width: 100%;"></a></p>
<p>Change_model.ipynb可以直接改变部署的模型，可以用于测试用, 运行一次10秒左右。</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%876.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%876.png" alt="" style="max-width: 100%;"></a></p>
<p>改变json_中model_path中的内容，运行后将会直接改变部署的模型。用于测试比较管用。改变模型后，可以结合dtest使用。</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%877.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%877.png" alt="" style="max-width: 100%;"></a></p>
<p>redis.ipynb用于敏感词数据库的操作。其中包括删除命令，请谨慎使用。
test_deploy.ipynb 用于测试部署的模型。</p>
<p>训练得到的checkpoints会保存到<code>checkpoints</code> 文件夹中</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%878.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%878.png" alt="" style="max-width: 100%;"></a></p>
<h4><a id="user-content-测试相关" class="anchor" aria-hidden="true" href="#测试相关"><span aria-hidden="true" class="octicon octicon-link"></span></a>测试相关</h4>
<p>dtest &lt;问题&gt; 可以直接与模型对话。(dtest stands for deploy test)</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%879.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%879.png" alt="" style="max-width: 100%;"></a></p>
<p>敏感词检查工作流程：</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8710.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8710.png" alt="" style="max-width: 100%;"></a></p>
<p>使用 <code>dtest 开始训练</code> 将会直接开始训练，这里不推荐使用，因为会让对话接口完全无法使用。</p>
<h4><a id="user-content-显卡监控" class="anchor" aria-hidden="true" href="#显卡监控"><span aria-hidden="true" class="octicon octicon-link"></span></a>显卡监控</h4>
<p>输入gpu回车可以查看gpu使用状况</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8711.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8711.png" alt="" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8712.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8712.png" alt="" style="max-width: 100%;"></a></p>
<p>建议新建一个单独的窗口使用gpu命令。</p>
<h4><a id="user-content-模型信息" class="anchor" aria-hidden="true" href="#模型信息"><span aria-hidden="true" class="octicon octicon-link"></span></a>模型信息</h4>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8714.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8714.png" alt="" style="max-width: 100%;"></a></p>
<h4><a id="user-content-补充" class="anchor" aria-hidden="true" href="#补充"><span aria-hidden="true" class="octicon octicon-link"></span></a>补充</h4>
<p>训练后的数据会被放在 trained_data中：</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8716.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8716.png" alt="" style="max-width: 100%;"></a></p>
<h4><a id="user-content-常见bug" class="anchor" aria-hidden="true" href="#常见bug"><span aria-hidden="true" class="octicon octicon-link"></span></a>常见bug</h4>
<p>Training_log.log中若有这个错误：</p>
<p><code>AssertionError: Provided path xxx does not contain a LoRA weight.</code></p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8717.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8717.png" alt="" style="max-width: 100%;"></a></p>
<p>说明起点checkpoint不存在或者起点checkpoint上次训练失败了，改变起点<code>last_checkpoint</code>即可解决问题.</p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8718.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%8718.png" alt="" style="max-width: 100%;"></a></p>
<h2><a id="user-content-前端训练半自动训练不推荐" class="anchor" aria-hidden="true" href="#前端训练半自动训练不推荐"><span aria-hidden="true" class="octicon octicon-link"></span></a>前端训练/半自动训练(不推荐)</h2>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%871.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%871.png" alt="" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%872_.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/%E5%9B%BE%E7%89%872_.png" alt="" style="max-width: 100%;"></a></p>
<blockquote>
<p>注: 训练模型时模型对话接口将会完全停止，请谨慎使用</p>
</blockquote>
<blockquote>
<p>正向“教导”AI模型较为简单，但要将模型反向”矫正”过来非常困难。所以，数据质量很重要，对模型姓名、模型开发者等重要背景信息，需要提前做出统一决定再进行训练(比如，是叫小薯条，还是叫薯遇)。您进行的每一次训练都举足轻重。如果模型出现了一些问题，只能通过回退到上一个模型检查点来解决。</p>
</blockquote>
<h2><a id="user-content-训练接口" class="anchor" aria-hidden="true" href="#训练接口"><span aria-hidden="true" class="octicon octicon-link"></span></a>训练接口</h2>
<ul>
<li>
<p>temp_data: 训练接口获得的前端数据的存储位置</p>
<ul>
<li>会以 Loovee-&lt;当日日期&gt; 的格式存储</li>
<li>其中的训练数据将会以类似 <code>2023-08-08-16:57:56.json</code> 的 <code>日期-时间</code> 命名格式存储</li>
</ul>
</li>
<li>
<p>trained_data: 已训练过的数据</p>
</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/images/docs/%E4%B9%90%E5%94%AF/Snipaste_2023-08-24_16-19-00.png"><img src="/images/docs/%E4%B9%90%E5%94%AF/Snipaste_2023-08-24_16-19-00.png" alt="" style="max-width: 100%;"></a></p>

</article>
<div>
</div>
</div>
</html>